"""
Embeddingå¢å¼ºæ¨èæœåŠ¡

æ ¸å¿ƒæµç¨‹:
1. LLMç”Ÿæˆå•†å“è¯­ä¹‰æè¿°
2. OpenAI Embedding APIç”Ÿæˆå‘é‡
3. å‘é‡ç›¸ä¼¼åº¦å¬å›
4. è®°å½•å®Œæ•´æ¨ç†è¿‡ç¨‹

ä½¿ç”¨OpenAI text-embedding-3-smallæ¨¡å‹æ›¿ä»£TF-IDF
"""
import json
import os
import time
from pathlib import Path
from typing import Optional
import numpy as np

from app.models import MenuItem, Category, Temperature
from app.data import MENU_ITEMS
from app.llm_service import llm_service, get_embedding_service


# ç¼“å­˜æ–‡ä»¶è·¯å¾„
CACHE_DIR = Path(__file__).parent / "cache"
ITEM_EMBEDDINGS_CACHE = CACHE_DIR / "item_embeddings.json"


class RealLLMService:
    """çœŸå®LLMæœåŠ¡ - è°ƒç”¨OpenAI/Claude API"""

    def __init__(self):
        self.llm = llm_service
        self.provider_info = self.llm.get_info()

        self.persona_templates = {
            "å¥åº·è¾¾äºº": {
                "description": "æ³¨é‡å¥åº·å…»ç”Ÿï¼Œåå¥½ä½ç³–ä½å¡ï¼Œå…³æ³¨è¥å…»æˆåˆ†",
                "base_keywords": ["ä½å¡", "å¥åº·", "æ— ç³–", "æ¤ç‰©åŸº", "ç‡•éº¦å¥¶"],
                "avoid": ["é«˜ç³–", "å¥¶æ²¹", "ç”œèœœ"]
            },
            "å’–å•¡é‡åº¦ç”¨æˆ·": {
                "description": "æ¯æ—¥å’–å•¡åˆšéœ€ï¼Œè¿½æ±‚å’–å•¡å› å«é‡å’Œæµ“éƒå£æ„Ÿ",
                "base_keywords": ["æµ“éƒ", "æç¥", "å’–å•¡", "æµ“ç¼©", "ç¾å¼"],
                "avoid": ["æ— å’–å•¡å› ", "èŒ¶é¥®"]
            },
            "ç”œå“çˆ±å¥½è€…": {
                "description": "å–œæ¬¢ç”œèœœå£æ„Ÿï¼Œæ³¨é‡é¢œå€¼å’Œæ‹ç…§åˆ†äº«",
                "base_keywords": ["ç”œèœœ", "ç½‘çº¢", "é¢œå€¼", "å¥¶æ²¹", "ç„¦ç³–"],
                "avoid": ["è‹¦", "æ— ç³–"]
            },
            "å°é²œæ´¾": {
                "description": "å–œæ¬¢å°è¯•æ–°å“ï¼Œè¿½æ±‚ç‹¬ç‰¹ä½“éªŒ",
                "base_keywords": ["æ–°å“", "é™å®š", "åˆ›æ–°", "ç‰¹è‰²", "ç‹¬å®¶"],
                "avoid": []
            },
            "å®ç”¨ä¸»ä¹‰": {
                "description": "æ³¨é‡æ€§ä»·æ¯”ï¼Œåå¥½ç»å…¸æ¬¾å¼",
                "base_keywords": ["ç»å…¸", "å®æƒ ", "å¤§æ¯", "äººæ°”"],
                "avoid": ["æ˜‚è´µ", "èŠ±å“¨"]
            },
            "å…»ç”Ÿç™½é¢†": {
                "description": "åŠå…¬å®¤å·¥ä½œè€…ï¼Œéœ€è¦æç¥ä½†ä¹Ÿå…³æ³¨å¥åº·",
                "base_keywords": ["æç¥", "ä½ç³–", "ç‡•éº¦å¥¶", "å·¥ä½œ", "ä¸‹åˆèŒ¶"],
                "avoid": ["é«˜ç³–", "å†°"]
            }
        }

    def generate_item_description(self, item: MenuItem) -> dict:
        """ä½¿ç”¨LLMç”Ÿæˆå•†å“çš„è¯­ä¹‰æè¿°"""
        start_time = time.time()

        prompt = f"""è¯·ä¸ºä»¥ä¸‹æ˜Ÿå·´å…‹é¥®å“ç”Ÿæˆè¯¦ç»†çš„è¯­ä¹‰æè¿°ã€‚

é¥®å“ä¿¡æ¯ï¼š
- åç§°ï¼š{item.name} ({item.english_name})
- åˆ†ç±»ï¼š{item.category.value}
- ä»·æ ¼ï¼šÂ¥{item.base_price}
- æè¿°ï¼š{item.description}
- å¡è·¯é‡Œï¼š{item.calories}
- æ ‡ç­¾ï¼š{', '.join(item.tags)}
- å¯é€‰æ¸©åº¦ï¼š{', '.join([t.value for t in item.available_temperatures])}
- æ˜¯å¦æ–°å“ï¼š{'æ˜¯' if item.is_new else 'å¦'}

è¯·è¾“å‡ºJSONæ ¼å¼ï¼š
{{
    "semantic_description": "100å­—ä»¥å†…çš„è¯¦ç»†æè¿°ï¼ŒåŒ…å«å£å‘³ã€é€‚åˆäººç¾¤ã€åœºæ™¯",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...]
}}"""

        result = self.llm.generate_json(prompt, "ä½ æ˜¯å’–å•¡å“é‰´ä¸“å®¶")
        elapsed_time = time.time() - start_time

        content = result["content"]
        if isinstance(content, dict) and "semantic_description" in content:
            return {
                "sku": item.sku,
                "name": item.name,
                "semantic_description": content.get("semantic_description", item.description),
                "keywords": content.get("keywords", item.tags),
                "processing_time_ms": round(elapsed_time * 1000, 2),
                "llm_model": result.get("model", "unknown"),
                "provider": result.get("provider", "unknown")
            }
        else:
            return self._fallback_item_description(item, elapsed_time)

    def _fallback_item_description(self, item: MenuItem, elapsed_time: float) -> dict:
        """é™çº§æè¿°ç”Ÿæˆ"""
        taste_mapping = {
            "å’–å•¡": ["é†‡åš", "é¦™æµ“", "å’–å•¡å› ", "æç¥"],
            "èŒ¶é¥®": ["æ¸…æ–°", "èŒ¶é¦™", "èˆ’ç¼“"],
            "æ˜Ÿå†°ä¹": ["å†°çˆ½", "é¡ºæ»‘", "ç”œèœœ"],
            "æ¸…çˆ½ç³»åˆ—": ["æ¸…çˆ½", "æœé¦™", "æ°”æ³¡"],
            "é£Ÿå“": ["é¦™è„†", "ç¾å‘³", "æ­é…"]
        }

        keywords = (
            taste_mapping.get(item.category.value, []) +
            item.tags +
            [item.category.value]
        )

        return {
            "sku": item.sku,
            "name": item.name,
            "semantic_description": item.description,
            "keywords": keywords,
            "processing_time_ms": round(elapsed_time * 1000, 2),
            "llm_model": "fallback",
            "provider": "local"
        }

    def generate_user_profile(
        self,
        persona_type: str,
        custom_tags: list[str] = None,
        customization_preference: dict = None
    ) -> dict:
        """ä½¿ç”¨LLMç”Ÿæˆç”¨æˆ·ç”»åƒï¼ˆæ”¯æŒèå…¥å®¢åˆ¶åŒ–åå¥½ï¼‰"""
        start_time = time.time()

        base_persona = self.persona_templates.get(
            persona_type,
            self.persona_templates["å®ç”¨ä¸»ä¹‰"]
        )

        all_keywords = base_persona["base_keywords"].copy()
        if custom_tags:
            all_keywords.extend(custom_tags)

        # ä»å®¢åˆ¶åŒ–åå¥½æå–å…³é”®è¯
        customization_keywords = []
        if customization_preference:
            # æ¸©åº¦åå¥½
            temp_pref = customization_preference.get("temperature", {})
            if temp_pref:
                top_temp = max(temp_pref.items(), key=lambda x: x[1])[0] if temp_pref else None
                if top_temp:
                    temp_map = {"HOT": "çƒ­é¥®", "ICED": "å†°é¥®", "WARM": "æ¸©é¥®"}
                    temp_display = temp_map.get(top_temp.upper(), top_temp)
                    ratio = temp_pref.get(top_temp, 0)
                    if ratio > 0.5:
                        customization_keywords.append(f"åå¥½{temp_display}")

            # å¥¶ç±»åå¥½
            milk_pref = customization_preference.get("milk_type", {})
            if milk_pref:
                top_milk = max(milk_pref.items(), key=lambda x: x[1])[0] if milk_pref else None
                if top_milk:
                    ratio = milk_pref.get(top_milk, 0)
                    if ratio > 0.4:
                        milk_map = {
                            "OAT": "ç‡•éº¦å¥¶çˆ±å¥½è€…", "SOY": "è±†å¥¶çˆ±å¥½è€…",
                            "COCONUT": "æ¤°å¥¶çˆ±å¥½è€…", "SKIM": "ä½è„‚åå¥½"
                        }
                        milk_display = milk_map.get(top_milk.upper())
                        if milk_display:
                            customization_keywords.append(milk_display)

            # ç³–åº¦åå¥½
            sugar_pref = customization_preference.get("sugar_level", {})
            if sugar_pref:
                top_sugar = max(sugar_pref.items(), key=lambda x: x[1])[0] if sugar_pref else None
                if top_sugar:
                    ratio = sugar_pref.get(top_sugar, 0)
                    if ratio > 0.4:
                        sugar_map = {
                            "NONE": "æ— ç³–æ§ç³–", "LIGHT": "å¾®ç³–åå¥½",
                            "HALF": "åŠç³–åå¥½", "LESS": "å°‘ç³–åå¥½"
                        }
                        sugar_display = sugar_map.get(top_sugar.upper())
                        if sugar_display:
                            customization_keywords.append(sugar_display)

        # åˆå¹¶å®¢åˆ¶åŒ–å…³é”®è¯
        all_keywords.extend(customization_keywords)

        # æ„å»ºå®¢åˆ¶åŒ–åå¥½æè¿°
        customization_hint = ""
        if customization_keywords:
            customization_hint = f"\nå®¢åˆ¶åŒ–ä¹ æƒ¯ï¼š{', '.join(customization_keywords)}"

        prompt = f"""åˆ†æç”¨æˆ·ç”»åƒï¼Œç”Ÿæˆé¥®å“åå¥½æè¿°ã€‚

ç”¨æˆ·ç±»å‹ï¼š{persona_type}
åŸºç¡€æè¿°ï¼š{base_persona["description"]}
åå¥½å…³é”®è¯ï¼š{', '.join(all_keywords)}{customization_hint}

è¾“å‡ºJSONï¼š
{{
    "enhanced_description": "30å­—æè¿°",
    "search_query": "ç”¨äºæœç´¢åŒ¹é…é¥®å“çš„æŸ¥è¯¢è¯­å¥ï¼Œ50å­—ä»¥å†…"
}}"""

        result = self.llm.generate_json(prompt, "ä½ æ˜¯ç”¨æˆ·ç ”ç©¶ä¸“å®¶")
        elapsed_time = time.time() - start_time

        content = result["content"]
        if isinstance(content, dict) and "search_query" in content:
            return {
                "persona_type": persona_type,
                "description": content.get("enhanced_description", base_persona["description"]),
                "keywords": all_keywords,
                "customization_keywords": customization_keywords,
                "search_query": content.get("search_query", " ".join(all_keywords)),
                "avoid_keywords": base_persona["avoid"],
                "processing_time_ms": round(elapsed_time * 1000, 2),
                "llm_model": result.get("model", "unknown"),
                "provider": result.get("provider", "unknown")
            }
        else:
            return {
                "persona_type": persona_type,
                "description": base_persona["description"],
                "keywords": all_keywords,
                "customization_keywords": customization_keywords,
                "search_query": " ".join(all_keywords),
                "avoid_keywords": base_persona["avoid"],
                "processing_time_ms": round(elapsed_time * 1000, 2),
                "llm_model": "fallback",
                "provider": "local"
            }

    def generate_recommendation_reason(
        self,
        item: MenuItem,
        user_profile: dict,
        match_score: float,
        use_llm: bool = True,
        suggested_customization: dict = None
    ) -> dict:
        """ç”Ÿæˆæ¨èç†ç”±ï¼ˆå¯å«å®¢åˆ¶åŒ–å»ºè®®ï¼‰"""
        start_time = time.time()

        if not use_llm:
            return self._quick_recommendation_reason(item, user_profile, match_score, start_time, suggested_customization)

        # æ„å»ºå®¢åˆ¶åŒ–æè¿°
        customization_hint = ""
        if suggested_customization and suggested_customization.get("suggested_customization"):
            custom = suggested_customization["suggested_customization"]
            custom_parts = []
            if custom.get("temperature"):
                temp_map = {"HOT": "çƒ­", "ICED": "å†°", "WARM": "æ¸©"}
                temp = custom["temperature"]
                custom_parts.append(temp_map.get(temp.upper(), temp))
            if custom.get("milk_type"):
                milk_map = {"OAT": "ç‡•éº¦å¥¶", "WHOLE": "å…¨è„‚å¥¶", "SKIM": "è„±è„‚å¥¶", "SOY": "è±†å¥¶", "COCONUT": "æ¤°å¥¶"}
                milk = custom["milk_type"]
                if milk.upper() not in ["NONE", "WHOLE"]:
                    custom_parts.append(milk_map.get(milk.upper(), milk))
            if custom.get("sugar_level"):
                sugar_map = {"NONE": "æ— ç³–", "LIGHT": "å¾®ç³–", "HALF": "åŠç³–", "LESS": "å°‘ç³–"}
                sugar = custom["sugar_level"]
                if sugar.upper() != "FULL":
                    custom_parts.append(sugar_map.get(sugar.upper(), sugar))
            if custom_parts:
                customization_hint = f"\næ¨èé…ç½®ï¼š{'+'.join(custom_parts)}ï¼ˆåŸºäºç”¨æˆ·ä¹ æƒ¯ï¼‰"

        prompt = f"""ä¸ºç”¨æˆ·ç”Ÿæˆé¥®å“æ¨èç†ç”±ã€‚

ç”¨æˆ·ï¼š{user_profile.get('persona_type')}ï¼Œåå¥½{', '.join(user_profile.get('keywords', [])[:3])}
é¥®å“ï¼š{item.name}ï¼Œ{item.description}
åŒ¹é…åº¦ï¼š{match_score:.0%}{customization_hint}

è¾“å‡ºJSONï¼š{{"reason": "15-20å­—æ¨èç†ç”±ï¼ˆå¯å«å®¢åˆ¶åŒ–å»ºè®®ï¼‰", "highlight": "æ ¸å¿ƒå–ç‚¹"}}"""

        result = self.llm.generate_json(prompt, "ä½ æ˜¯æ˜Ÿå·´å…‹åº—å‘˜ï¼Œè¯­æ°”äº²åˆ‡")
        elapsed_time = time.time() - start_time

        content = result["content"]
        if isinstance(content, dict) and "reason" in content:
            return {
                "reason": content.get("reason", "ä¸ºæ‚¨ç²¾é€‰æ¨è"),
                "highlight": content.get("highlight", ""),
                "confidence": "high" if match_score > 0.6 else "medium",
                "processing_time_ms": round(elapsed_time * 1000, 2),
                "llm_model": result.get("model", "unknown"),
                "provider": result.get("provider", "unknown")
            }
        else:
            return self._quick_recommendation_reason(item, user_profile, match_score, start_time, suggested_customization)

    def _quick_recommendation_reason(self, item, user_profile, match_score, start_time, suggested_customization=None):
        """å¿«é€Ÿç”Ÿæˆæ¨èç†ç”±"""
        reasons = []
        item_keywords = set(item.tags)
        user_keywords = set(user_profile.get("keywords", []))
        matched = item_keywords & user_keywords

        if matched:
            reasons.append(f"ç¬¦åˆæ‚¨å¯¹ã€Œ{list(matched)[0]}ã€çš„åå¥½")
        if item.is_new:
            reasons.append("æ–°å“æ¨è")
        if item.is_seasonal:
            reasons.append("å­£èŠ‚é™å®š")
        if item.calories < 100:
            reasons.append(f"ä»…{item.calories}å¡")

        # æ·»åŠ å®¢åˆ¶åŒ–å»ºè®®åˆ°ç†ç”±
        if suggested_customization and suggested_customization.get("reason"):
            custom_reason = suggested_customization["reason"]
            if custom_reason and custom_reason != "ç»¼åˆæ‚¨çš„å†å²åå¥½æ¨è":
                reasons.append(custom_reason.split("ï¼›")[0])  # å–ç¬¬ä¸€ä¸ªå®¢åˆ¶åŒ–åŸå› 

        if not reasons:
            reasons.append("çƒ­é—¨æ¨è")

        return {
            "reason": "ï¼›".join(reasons[:2]),
            "highlight": list(matched)[0] if matched else "",
            "confidence": "high" if match_score > 0.6 else "medium",
            "processing_time_ms": round((time.time() - start_time) * 1000, 2),
            "llm_model": "rule-based",
            "provider": "local"
        }


class OpenAIEmbeddingVectorService:
    """ä½¿ç”¨OpenAI Embedding APIçš„å‘é‡æœåŠ¡"""

    def __init__(self):
        self.embedding_service = get_embedding_service()
        self.llm_service = RealLLMService()
        self.item_embeddings: dict[str, np.ndarray] = {}
        self.item_texts: dict[str, dict] = {}
        self._initialize_embeddings()

    def _initialize_embeddings(self):
        """åˆå§‹åŒ–å•†å“å‘é‡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        print("ğŸ”„ åˆå§‹åŒ–å•†å“Embedding...")

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        if self._load_cache():
            print(f"âœ… ä»ç¼“å­˜åŠ è½½äº† {len(self.item_embeddings)} ä¸ªå•†å“Embedding")
            return

        # ç”Ÿæˆæ–°çš„embedding
        print("ğŸ“ ç”Ÿæˆå•†å“æè¿°å’ŒEmbeddingï¼ˆé¦–æ¬¡å¯åŠ¨è¾ƒæ…¢ï¼‰...")

        texts_to_embed = []
        skus = []

        for item in MENU_ITEMS:
            # ä½¿ç”¨LLMç”Ÿæˆæè¿°
            desc = self.llm_service.generate_item_description(item)
            self.item_texts[item.sku] = desc

            # æ„å»ºå®¢åˆ¶åŒ–ç‰¹å¾æè¿°
            customization_features = []
            if item.customization_constraints:
                constraints = item.customization_constraints
                # å¥¶ç±»é€‰é¡¹
                if constraints.available_milk_types:
                    milk_names = {
                        "OAT": "ç‡•éº¦å¥¶", "SOY": "è±†å¥¶", "COCONUT": "æ¤°å¥¶",
                        "SKIM": "è„±è„‚å¥¶", "WHOLE": "å…¨è„‚å¥¶"
                    }
                    available_milks = [
                        milk_names.get(m.value if hasattr(m, 'value') else m.upper(), m)
                        for m in constraints.available_milk_types
                        if (m.value if hasattr(m, 'value') else m.upper()) != "NONE"
                    ]
                    if available_milks:
                        customization_features.append(f"å¯é€‰{'/'.join(available_milks[:3])}")
                # ç³–åº¦é€‰é¡¹
                if constraints.available_sugar_levels:
                    sugar_names = {"NONE": "æ— ç³–", "LIGHT": "å¾®ç³–", "HALF": "åŠç³–", "LESS": "å°‘ç³–"}
                    low_sugar_options = [
                        sugar_names.get(s.value if hasattr(s, 'value') else s.upper())
                        for s in constraints.available_sugar_levels
                        if (s.value if hasattr(s, 'value') else s.upper()) in ["NONE", "LIGHT", "HALF", "LESS"]
                    ]
                    if low_sugar_options:
                        customization_features.append(f"æ”¯æŒ{'/'  .join(low_sugar_options[:2])}")
                # åŠ æµ“ç¼©
                if constraints.supports_espresso_adjustment:
                    customization_features.append("å¯åŠ æµ“ç¼©")
                # å¥¶æ²¹é¡¶
                if constraints.supports_whipped_cream:
                    customization_features.append("å¯åŠ å¥¶æ²¹é¡¶")

            customization_text = f"å®¢åˆ¶åŒ–ï¼š{', '.join(customization_features)}ã€‚" if customization_features else ""

            # æ„å»ºç”¨äºembeddingçš„æ–‡æœ¬ï¼ˆå¢å¼ºç‰ˆå«å®¢åˆ¶åŒ–ç‰¹å¾ï¼‰
            embed_text = f"{item.name}ã€‚{desc['semantic_description']}ã€‚" \
                        f"åˆ†ç±»ï¼š{item.category.value}ã€‚" \
                        f"æ ‡ç­¾ï¼š{', '.join(item.tags)}ã€‚" \
                        f"{'æ–°å“ã€‚' if item.is_new else ''}" \
                        f"{'å­£èŠ‚é™å®šã€‚' if item.is_seasonal else ''}" \
                        f"{item.calories}å¡è·¯é‡Œã€‚Â¥{item.base_price}ã€‚" \
                        f"{customization_text}"

            texts_to_embed.append(embed_text)
            skus.append(item.sku)
            print(f"   ğŸ“¦ {item.name}")

        # æ‰¹é‡è·å–embedding
        print("ğŸ”¢ è°ƒç”¨OpenAI Embedding API...")
        embeddings = self.embedding_service.get_embeddings(texts_to_embed)

        for sku, embedding in zip(skus, embeddings):
            self.item_embeddings[sku] = np.array(embedding)

        # ä¿å­˜ç¼“å­˜
        self._save_cache()
        print(f"âœ… ç”Ÿæˆå¹¶ç¼“å­˜äº† {len(self.item_embeddings)} ä¸ªå•†å“Embedding")

    def _load_cache(self) -> bool:
        """ä»ç¼“å­˜åŠ è½½embedding"""
        if not ITEM_EMBEDDINGS_CACHE.exists():
            return False

        try:
            with open(ITEM_EMBEDDINGS_CACHE, "r") as f:
                cache = json.load(f)

            # éªŒè¯ç¼“å­˜ç‰ˆæœ¬
            if cache.get("version") != "v3":
                return False

            for sku, data in cache.get("items", {}).items():
                self.item_embeddings[sku] = np.array(data["embedding"])
                self.item_texts[sku] = data["text_info"]

            return len(self.item_embeddings) == len(MENU_ITEMS)
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            return False

    def _save_cache(self):
        """ä¿å­˜embeddingåˆ°ç¼“å­˜"""
        CACHE_DIR.mkdir(exist_ok=True)

        cache = {
            "version": "v3",
            "model": self.embedding_service.model,
            "items": {}
        }

        for sku, embedding in self.item_embeddings.items():
            cache["items"][sku] = {
                "embedding": embedding.tolist(),
                "text_info": self.item_texts.get(sku, {})
            }

        with open(ITEM_EMBEDDINGS_CACHE, "w") as f:
            json.dump(cache, f, ensure_ascii=False)

    def get_user_embedding(self, user_profile: dict) -> np.ndarray:
        """è·å–ç”¨æˆ·ç”»åƒçš„embedding"""
        # ä½¿ç”¨LLMç”Ÿæˆçš„search_queryä½œä¸ºembeddingè¾“å…¥
        search_query = user_profile.get("search_query", "")
        if not search_query:
            search_query = " ".join(user_profile.get("keywords", []))

        embedding = self.embedding_service.get_embedding(search_query)
        return np.array(embedding)

    def calculate_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        if norm1 == 0 or norm2 == 0:
            return 0.0
        return float(dot_product / (norm1 * norm2))


class EmbeddingRecommendationEngine:
    """Embeddingå¢å¼ºæ¨èå¼•æ“"""

    def __init__(self):
        self.llm_service = RealLLMService()
        self.vector_service = OpenAIEmbeddingVectorService()
        self.menu_items = {item.sku: item for item in MENU_ITEMS}

        # å»¶è¿Ÿå¯¼å…¥å®éªŒæœåŠ¡ï¼ˆé¿å…å¾ªç¯ä¾èµ–ï¼‰
        self._experiment_services = None

    @property
    def experiment_services(self):
        """æ‡’åŠ è½½å®éªŒç›¸å…³æœåŠ¡"""
        if self._experiment_services is None:
            from app.experiment_service import (
                ab_test_service, behavior_service, session_service, explainability_service
            )
            self._experiment_services = {
                "ab_test": ab_test_service,
                "behavior": behavior_service,
                "session": session_service,
                "explainability": explainability_service
            }
        return self._experiment_services

    def recommend(
        self,
        persona_type: str,
        custom_tags: list[str] = None,
        context: dict = None,
        top_k: int = 6,
        use_llm_for_reasons: bool = True
    ) -> dict:
        """æ‰§è¡Œæ¨è"""
        start_time = time.time()
        reasoning_steps = []
        llm_calls = []

        # Step 1: ç”Ÿæˆç”¨æˆ·ç”»åƒ
        step1_start = time.time()
        user_profile = self.llm_service.generate_user_profile(persona_type, custom_tags)

        llm_calls.append({
            "step": 1,
            "type": "user_profile",
            "model": user_profile.get("llm_model"),
            "provider": user_profile.get("provider"),
            "latency_ms": user_profile.get("processing_time_ms", 0)
        })

        reasoning_steps.append({
            "step": 1,
            "name": "ç”¨æˆ·ç”»åƒç”Ÿæˆ",
            "description": f"åˆ†æç”¨æˆ·ã€Œ{persona_type}ã€ç”Ÿæˆæœç´¢query",
            "input": {"persona_type": persona_type, "custom_tags": custom_tags},
            "output": {
                "search_query": user_profile.get("search_query", "")[:50],
                "keywords": user_profile.get("keywords", [])[:5]
            },
            "duration_ms": round((time.time() - step1_start) * 1000, 2),
            "model": user_profile.get("llm_model"),
            "provider": user_profile.get("provider")
        })

        # Step 2: ç”¨æˆ·å‘é‡åŒ– (OpenAI Embedding)
        step2_start = time.time()
        user_embedding = self.vector_service.get_user_embedding(user_profile)

        embedding_info = self.vector_service.embedding_service.get_info()
        reasoning_steps.append({
            "step": 2,
            "name": "ç”¨æˆ·å‘é‡åŒ–",
            "description": f"ä½¿ç”¨ {embedding_info['model']} ç”Ÿæˆç”¨æˆ·å‘é‡",
            "input": {"query": user_profile.get("search_query", "")[:30] + "..."},
            "output": {
                "vector_dim": len(user_embedding),
                "model": embedding_info["model"]
            },
            "duration_ms": round((time.time() - step2_start) * 1000, 2),
            "model": embedding_info["model"],
            "provider": "openai"
        })

        # Step 3: å‘é‡å¬å›
        step3_start = time.time()
        candidates = []
        for sku, item_embedding in self.vector_service.item_embeddings.items():
            similarity = self.vector_service.calculate_similarity(
                user_embedding, item_embedding
            )
            candidates.append({
                "sku": sku,
                "similarity": similarity
            })

        candidates.sort(key=lambda x: x["similarity"], reverse=True)
        reasoning_steps.append({
            "step": 3,
            "name": "è¯­ä¹‰å‘é‡å¬å›",
            "description": f"ä»{len(candidates)}ä¸ªå•†å“ä¸­è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦",
            "input": {"total_items": len(candidates)},
            "output": {
                "top_candidates": [
                    {"sku": c["sku"], "name": self.menu_items[c["sku"]].name,
                     "score": round(c["similarity"], 4)}
                    for c in candidates[:top_k]
                ]
            },
            "duration_ms": round((time.time() - step3_start) * 1000, 2),
            "model": "Cosine Similarity",
            "provider": "numpy"
        })

        # Step 4: ä¸šåŠ¡è§„åˆ™é‡æ’
        step4_start = time.time()
        reranked = []
        for candidate in candidates[:top_k * 2]:
            item = self.menu_items[candidate["sku"]]
            score = candidate["similarity"]

            # ä¸šåŠ¡åŠ æƒ
            if item.is_new:
                score *= 1.15
            if item.is_seasonal:
                score *= 1.1
            if any(tag in user_profile.get("avoid_keywords", []) for tag in item.tags):
                score *= 0.5

            # ä¸Šä¸‹æ–‡åŠ æƒ
            if context:
                if context.get("time_of_day") == "morning" and item.category == Category.COFFEE:
                    score *= 1.1
                if context.get("weather") == "hot" and Temperature.ICED in item.available_temperatures:
                    score *= 1.05

            reranked.append({
                "sku": candidate["sku"],
                "base_score": candidate["similarity"],
                "final_score": score
            })

        reranked.sort(key=lambda x: x["final_score"], reverse=True)
        reasoning_steps.append({
            "step": 4,
            "name": "ä¸šåŠ¡è§„åˆ™é‡æ’",
            "description": "åº”ç”¨æ–°å“ã€å­£èŠ‚ã€åå¥½è§„åˆ™è°ƒæ•´",
            "input": {"candidates_count": len(candidates[:top_k * 2])},
            "output": {
                "reranked_top": [
                    {"sku": r["sku"], "name": self.menu_items[r["sku"]].name,
                     "base": round(r["base_score"], 3), "final": round(r["final_score"], 3)}
                    for r in reranked[:top_k]
                ]
            },
            "duration_ms": round((time.time() - step4_start) * 1000, 2),
            "model": "Rule-based",
            "provider": "custom"
        })

        # Step 5: ç”Ÿæˆæ¨èç†ç”±
        step5_start = time.time()
        recommendations = []
        reason_llm_calls = []

        for i, ranked in enumerate(reranked[:top_k]):
            item = self.menu_items[ranked["sku"]]

            use_llm = use_llm_for_reasons and i < 3
            reason_result = self.llm_service.generate_recommendation_reason(
                item, user_profile, ranked["final_score"], use_llm=use_llm
            )

            if use_llm and reason_result.get("provider") != "local":
                reason_llm_calls.append({
                    "item": item.name,
                    "model": reason_result.get("llm_model"),
                    "latency_ms": reason_result.get("processing_time_ms", 0)
                })

            item_desc = self.vector_service.item_texts.get(ranked["sku"], {})

            recommendations.append({
                "item": {
                    "sku": item.sku,
                    "name": item.name,
                    "english_name": item.english_name,
                    "category": item.category.value,
                    "base_price": item.base_price,
                    "description": item.description,
                    "calories": item.calories,
                    "tags": item.tags,
                    "is_new": item.is_new,
                    "is_seasonal": item.is_seasonal,
                    "available_temperatures": [t.value for t in item.available_temperatures],
                    "available_sizes": [s.value for s in item.available_sizes]
                },
                "match_score": round(ranked["final_score"], 4),
                "base_score": round(ranked["base_score"], 4),
                "reason": reason_result.get("reason", ""),
                "reason_highlight": reason_result.get("highlight", ""),
                "reason_confidence": reason_result.get("confidence", "medium"),
                "semantic_description": item_desc.get("semantic_description", ""),
                "llm_generated": reason_result.get("provider") != "local"
            })

        llm_calls.extend([{"step": 5, "type": "reason", **c} for c in reason_llm_calls])

        reasoning_steps.append({
            "step": 5,
            "name": "æ¨èç†ç”±ç”Ÿæˆ",
            "description": f"Top-{min(3, top_k)}ä½¿ç”¨LLM",
            "input": {"items_count": len(recommendations)},
            "output": {"llm_reasons": len(reason_llm_calls)},
            "duration_ms": round((time.time() - step5_start) * 1000, 2),
            "model": "GPT-4o-mini",
            "provider": "openai"
        })

        total_time = time.time() - start_time

        return {
            "user_profile": {
                "persona_type": persona_type,
                "description": user_profile.get("description", ""),
                "keywords": user_profile.get("keywords", []),
                "search_query": user_profile.get("search_query", ""),
                "avoid_keywords": user_profile.get("avoid_keywords", []),
                "custom_tags": custom_tags or []
            },
            "context": context or {},
            "reasoning_steps": reasoning_steps,
            "recommendations": recommendations,
            "llm_info": {
                "provider": self.llm_service.provider_info.get("provider"),
                "model": self.llm_service.provider_info.get("model"),
                "embedding_model": self.vector_service.embedding_service.model,
                "calls": llm_calls,
                "total_llm_calls": len(llm_calls)
            },
            "metrics": {
                "total_time_ms": round(total_time * 1000, 2),
                "candidates_evaluated": len(candidates),
                "final_recommendations": len(recommendations),
                "avg_match_score": round(
                    sum(r["match_score"] for r in recommendations) / len(recommendations),
                    4
                ) if recommendations else 0
            }
        }

    def get_available_personas(self) -> list[dict]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„ç”¨æˆ·ç”»åƒç±»å‹"""
        return [
            {
                "type": persona_type,
                "description": data["description"],
                "keywords": data["base_keywords"]
            }
            for persona_type, data in self.llm_service.persona_templates.items()
        ]

    def recommend_v2(
        self,
        persona_type: str,
        user_id: str = None,
        session_id: str = None,
        custom_tags: list[str] = None,
        context: dict = None,
        top_k: int = 6,
        use_llm_for_reasons: bool = True,
        enable_ab_test: bool = True,
        enable_behavior: bool = True,
        enable_session: bool = True,
        enable_explainability: bool = True
    ) -> dict:
        """
        å¢å¼ºç‰ˆæ¨è - é›†æˆA/Bæµ‹è¯•ã€ç”¨æˆ·è¡Œä¸ºã€Sessionä¸ªæ€§åŒ–å’Œè§£é‡Šæ€§å¢å¼º

        æ–°å¢å‚æ•°:
        - user_id: ç”¨æˆ·IDï¼ˆç”¨äºå†å²è¡Œä¸ºå’ŒA/Båˆ†ç»„ï¼‰
        - session_id: ä¼šè¯IDï¼ˆç”¨äºå®æ—¶ä¸ªæ€§åŒ–ï¼‰
        - enable_ab_test: æ˜¯å¦å¯ç”¨A/Bæµ‹è¯•
        - enable_behavior: æ˜¯å¦å¯ç”¨å†å²è¡Œä¸ºåŠ æƒ
        - enable_session: æ˜¯å¦å¯ç”¨Sessionå®æ—¶ä¸ªæ€§åŒ–
        - enable_explainability: æ˜¯å¦ç”Ÿæˆè¯¦ç»†è§£é‡Š
        """
        start_time = time.time()
        reasoning_steps = []
        llm_calls = []

        # ç”Ÿæˆé»˜è®¤ID
        user_id = user_id or f"user_{int(time.time())}"
        session_id = session_id or f"session_{int(time.time())}"

        # === A/Bæµ‹è¯•åˆ†ç»„ ===
        experiment_info = {}
        if enable_ab_test:
            services = self.experiment_services
            rec_variant = services["ab_test"].get_variant("rec_algorithm", user_id)
            reason_variant = services["ab_test"].get_variant("reason_style", user_id)
            experiment_info = {
                "rec_algorithm": rec_variant,
                "reason_style": reason_variant
            }

        # Step 1: ç”Ÿæˆç”¨æˆ·ç”»åƒï¼ˆèå…¥å®¢åˆ¶åŒ–åå¥½ï¼‰
        step1_start = time.time()
        services = self.experiment_services

        # è·å–ç”¨æˆ·å®¢åˆ¶åŒ–åå¥½ï¼ˆç”¨äºå¢å¼ºç”¨æˆ·ç”»åƒç”Ÿæˆï¼‰
        customization_preference = None
        if enable_behavior:
            user_behavior_profile = services["behavior"].get_user_profile(user_id)
            customization_preference = user_behavior_profile.get("customization_preference", {})

        user_profile = self.llm_service.generate_user_profile(
            persona_type, custom_tags, customization_preference
        )

        llm_calls.append({
            "step": 1,
            "type": "user_profile",
            "model": user_profile.get("llm_model"),
            "provider": user_profile.get("provider"),
            "latency_ms": user_profile.get("processing_time_ms", 0)
        })

        reasoning_steps.append({
            "step": 1,
            "name": "ç”¨æˆ·ç”»åƒç”Ÿæˆ",
            "description": f"åˆ†æç”¨æˆ·ã€Œ{persona_type}ã€ç”Ÿæˆæœç´¢queryï¼ˆå«å®¢åˆ¶åŒ–åå¥½ï¼‰",
            "input": {
                "persona_type": persona_type,
                "custom_tags": custom_tags,
                "has_customization_pref": bool(customization_preference)
            },
            "output": {
                "search_query": user_profile.get("search_query", "")[:50],
                "keywords": user_profile.get("keywords", [])[:5],
                "customization_keywords": user_profile.get("customization_keywords", [])
            },
            "duration_ms": round((time.time() - step1_start) * 1000, 2),
            "model": user_profile.get("llm_model"),
            "provider": user_profile.get("provider")
        })

        # Step 2: ç”¨æˆ·å‘é‡åŒ–
        step2_start = time.time()
        user_embedding = self.vector_service.get_user_embedding(user_profile)
        embedding_info = self.vector_service.embedding_service.get_info()

        reasoning_steps.append({
            "step": 2,
            "name": "ç”¨æˆ·å‘é‡åŒ–",
            "description": f"ä½¿ç”¨ {embedding_info['model']} ç”Ÿæˆç”¨æˆ·å‘é‡",
            "input": {"query": user_profile.get("search_query", "")[:30] + "..."},
            "output": {"vector_dim": len(user_embedding), "model": embedding_info["model"]},
            "duration_ms": round((time.time() - step2_start) * 1000, 2),
            "model": embedding_info["model"],
            "provider": "openai"
        })

        # Step 3: å‘é‡å¬å›
        step3_start = time.time()
        candidates = []
        for sku, item_embedding in self.vector_service.item_embeddings.items():
            similarity = self.vector_service.calculate_similarity(user_embedding, item_embedding)
            candidates.append({"sku": sku, "similarity": similarity})

        candidates.sort(key=lambda x: x["similarity"], reverse=True)

        reasoning_steps.append({
            "step": 3,
            "name": "è¯­ä¹‰å‘é‡å¬å›",
            "description": f"ä»{len(candidates)}ä¸ªå•†å“ä¸­è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦",
            "input": {"total_items": len(candidates)},
            "output": {
                "top_candidates": [
                    {"sku": c["sku"], "name": self.menu_items[c["sku"]].name, "score": round(c["similarity"], 4)}
                    for c in candidates[:top_k]
                ]
            },
            "duration_ms": round((time.time() - step3_start) * 1000, 2),
            "model": "Cosine Similarity",
            "provider": "numpy"
        })

        # Step 4: å¤šå› ç´ åŠ æƒé‡æ’
        step4_start = time.time()
        services = self.experiment_services
        reranked = []

        for candidate in candidates[:top_k * 2]:
            item = self.menu_items[candidate["sku"]]
            base_score = candidate["similarity"]

            # ä¸šåŠ¡è§„åˆ™åŠ æƒ
            rule_multiplier = 1.0
            if item.is_new:
                rule_multiplier *= 1.15
            if item.is_seasonal:
                rule_multiplier *= 1.1
            if any(tag in user_profile.get("avoid_keywords", []) for tag in item.tags):
                rule_multiplier *= 0.5

            # === æ‰©å±•çš„ä¸Šä¸‹æ–‡åŠ æƒ ===
            if context:
                time_of_day = context.get("time_of_day")
                season = context.get("season")
                day_type = context.get("day_type")

                # æ—¶é—´æ®µè§„åˆ™
                if time_of_day == "morning":
                    if item.category == Category.COFFEE:
                        rule_multiplier *= 1.15  # æ—©æ™¨å’–å•¡åŠ æƒ
                    if item.category == Category.FOOD and "æ—©é¤" in item.tags:
                        rule_multiplier *= 1.2  # æ—©é¤é£Ÿå“åŠ æƒ
                elif time_of_day == "lunch":
                    if item.category == Category.FOOD:
                        rule_multiplier *= 1.1
                elif time_of_day == "afternoon":
                    if item.category == Category.TEA:
                        rule_multiplier *= 1.1  # ä¸‹åˆèŒ¶åŠ æƒ
                    if item.category == Category.FRAPPUCCINO:
                        rule_multiplier *= 1.1
                elif time_of_day == "evening":
                    if "æ— å’–å•¡å› " in item.tags:
                        rule_multiplier *= 1.15  # æ™šé—´æ— å’–å•¡å› åŠ æƒ
                    if item.category == Category.COFFEE:
                        rule_multiplier *= 0.9  # æ™šé—´å’–å•¡é™æƒ
                elif time_of_day == "night":
                    if item.category == Category.COFFEE:
                        rule_multiplier *= 0.8  # å¤œé—´å’–å•¡é™æƒ

                # å­£èŠ‚è§„åˆ™
                if season == "summer":
                    if Temperature.ICED in item.available_temperatures:
                        rule_multiplier *= 1.1
                    if "æ¸…çˆ½" in item.tags or "å†°çˆ½" in item.tags:
                        rule_multiplier *= 1.1
                elif season == "winter":
                    if Temperature.HOT in item.available_temperatures:
                        rule_multiplier *= 1.1
                    if "æ¸©æš–" in item.tags:
                        rule_multiplier *= 1.1

                # å‘¨æœ«è§„åˆ™
                if day_type == "weekend":
                    if item.is_new or item.is_seasonal:
                        rule_multiplier *= 1.1  # å‘¨æœ«æ›´æ„¿æ„å°æ–°

            # === A/Bæµ‹è¯•çœŸæ­£ç®—æ³•åˆ†æ”¯ ===
            rec_variant = experiment_info.get("rec_algorithm", {}).get("variant", "hybrid")

            # å†å²è¡Œä¸ºåŠ æƒï¼ˆä½¿ç”¨å¢å¼ºç‰ˆè®¢å•æƒé‡ï¼‰
            behavior_multiplier = 1.0
            order_boost_detail = None
            if enable_behavior and rec_variant in ["embedding_plus", "hybrid"]:
                # ä½¿ç”¨æ–°çš„è®¢å•æƒé‡APIè·å–è¯¦ç»†åˆ†è§£
                order_boost_detail = services["behavior"].get_order_based_recommendation_boost(
                    user_id, item.sku, item.category.value, item.tags, item.base_price
                )
                behavior_multiplier = order_boost_detail["total_boost"]

            # Sessionå®æ—¶ä¸ªæ€§åŒ–åŠ æƒï¼ˆä»… hybrid å˜ä½“å¯ç”¨ï¼‰
            session_multiplier = 1.0
            if enable_session and rec_variant == "hybrid":
                session_multiplier = services["session"].get_session_boost(
                    session_id, item.tags, item.category.value, item.base_price
                )

            # å®¢åˆ¶åŒ–åå¥½åŠ æƒï¼ˆä»… hybrid å˜ä½“å¯ç”¨ï¼‰
            customization_multiplier = 1.0
            customization_boost_detail = None
            if enable_behavior and rec_variant == "hybrid":
                # è·å–å•†å“å®¢åˆ¶åŒ–çº¦æŸ
                item_constraints = None
                if item.customization_constraints:
                    item_constraints = item.customization_constraints.model_dump()

                customization_boost_detail = services["behavior"].get_customization_based_boost(
                    user_id,
                    item_constraints,
                    [t.value for t in item.available_temperatures],
                    [s.value for s in item.available_sizes]
                )
                customization_multiplier = customization_boost_detail["total_boost"]

            # === å†·å¯åŠ¨ç­–ç•¥ ===
            cold_start_boost = 1.0
            is_cold_start = False
            if enable_behavior:
                user_behavior_profile = services["behavior"].get_user_profile(user_id)
                if user_behavior_profile.get("is_new_user", True):
                    is_cold_start = True
                    # 1. æ–°å“/å­£èŠ‚é™å®šé¢å¤–åŠ æƒ
                    if item.is_new:
                        cold_start_boost *= 1.2
                    if item.is_seasonal:
                        cold_start_boost *= 1.15
                    # 2. äººæ°”å•†å“åŠ æƒï¼ˆåŸºäºæ ‡ç­¾ï¼‰
                    if "äººæ°”" in item.tags:
                        cold_start_boost *= 1.15
                    if "ç»å…¸" in item.tags:
                        cold_start_boost *= 1.1

            # ç»¼åˆå¾—åˆ†
            final_score = base_score * rule_multiplier * behavior_multiplier * session_multiplier * customization_multiplier * cold_start_boost

            # è®¡ç®—åŒ¹é…çš„å…³é”®è¯
            user_keywords = set(user_profile.get("keywords", []))
            item_keywords = set(item.tags)
            matched_keywords = list(user_keywords & item_keywords)

            reranked.append({
                "sku": candidate["sku"],
                "base_score": base_score,
                "rule_multiplier": rule_multiplier,
                "behavior_multiplier": behavior_multiplier,
                "session_multiplier": session_multiplier,
                "customization_multiplier": customization_multiplier,
                "cold_start_boost": cold_start_boost,
                "is_cold_start": is_cold_start,
                "final_score": final_score,
                "matched_keywords": matched_keywords,
                "order_boost_detail": order_boost_detail,
                "customization_boost_detail": customization_boost_detail,
                "algorithm_variant": rec_variant
            })

        reranked.sort(key=lambda x: x["final_score"], reverse=True)

        reasoning_steps.append({
            "step": 4,
            "name": "å¤šå› ç´ åŠ æƒé‡æ’",
            "description": "ç»¼åˆä¸šåŠ¡è§„åˆ™ã€å†å²è¡Œä¸ºã€å®æ—¶åå¥½ã€å®¢åˆ¶åŒ–åŒ¹é…",
            "input": {
                "enable_behavior": enable_behavior,
                "enable_session": enable_session
            },
            "output": {
                "reranked_top": [
                    {
                        "sku": r["sku"],
                        "name": self.menu_items[r["sku"]].name,
                        "base": round(r["base_score"], 3),
                        "behavior": round(r["behavior_multiplier"], 2),
                        "session": round(r["session_multiplier"], 2),
                        "customization": round(r["customization_multiplier"], 2),
                        "final": round(r["final_score"], 3)
                    }
                    for r in reranked[:top_k]
                ]
            },
            "duration_ms": round((time.time() - step4_start) * 1000, 2),
            "model": "Multi-factor Reranking",
            "provider": "custom"
        })

        # Step 5: ç”Ÿæˆæ¨èç†ç”±å’Œè§£é‡Š
        step5_start = time.time()
        recommendations = []
        reason_llm_calls = []

        # æ ¹æ®A/Bæµ‹è¯•å†³å®šæ¨èç†ç”±é£æ ¼
        reason_style = "concise"
        if experiment_info.get("reason_style", {}).get("variant") == "detailed":
            reason_style = "detailed"

        for i, ranked in enumerate(reranked[:top_k]):
            item = self.menu_items[ranked["sku"]]
            item_desc = self.vector_service.item_texts.get(ranked["sku"], {})

            # ç”Ÿæˆæ¨èå®¢åˆ¶åŒ–ç»„åˆï¼ˆéœ€å…ˆäºæ¨èç†ç”±ç”Ÿæˆï¼Œä»¥ä¾¿èå…¥ç†ç”±ï¼‰
            suggested_customization = None
            if enable_behavior:
                item_constraints = None
                if item.customization_constraints:
                    item_constraints = item.customization_constraints.model_dump()

                suggested_customization = services["behavior"].get_suggested_customization_for_item(
                    user_id,
                    item.sku,
                    item_constraints,
                    [t.value for t in item.available_temperatures],
                    [s.value for s in item.available_sizes],
                    item.base_price
                )

            # ç”Ÿæˆæ¨èç†ç”±ï¼ˆèå…¥å®¢åˆ¶åŒ–å»ºè®®ï¼‰
            use_llm = use_llm_for_reasons and i < 3
            reason_result = self.llm_service.generate_recommendation_reason(
                item, user_profile, ranked["final_score"],
                use_llm=use_llm,
                suggested_customization=suggested_customization
            )

            if use_llm and reason_result.get("provider") != "local":
                reason_llm_calls.append({
                    "item": item.name,
                    "model": reason_result.get("llm_model"),
                    "latency_ms": reason_result.get("processing_time_ms", 0)
                })

            # ç”Ÿæˆè¯¦ç»†è§£é‡Š
            explanation = None
            if enable_explainability:
                explanation = services["explainability"].generate_detailed_explanation(
                    item={
                        "sku": item.sku,
                        "name": item.name,
                        "is_new": item.is_new,
                        "is_seasonal": item.is_seasonal,
                        "tags": item.tags
                    },
                    user_profile=user_profile,
                    match_score=ranked["final_score"],
                    session_boost=ranked["session_multiplier"],
                    behavior_boost=ranked["behavior_multiplier"],
                    embedding_similarity=ranked["base_score"],
                    matched_keywords=ranked["matched_keywords"],
                    experiment_info=experiment_info
                )

            recommendations.append({
                "item": {
                    "sku": item.sku,
                    "name": item.name,
                    "english_name": item.english_name,
                    "category": item.category.value,
                    "base_price": item.base_price,
                    "description": item.description,
                    "calories": item.calories,
                    "tags": item.tags,
                    "is_new": item.is_new,
                    "is_seasonal": item.is_seasonal,
                    "available_temperatures": [t.value for t in item.available_temperatures],
                    "available_sizes": [s.value for s in item.available_sizes]
                },
                "match_score": round(ranked["final_score"], 4),
                "base_score": round(ranked["base_score"], 4),
                "score_breakdown": {
                    "embedding_similarity": round(ranked["base_score"], 4),
                    "rule_multiplier": round(ranked["rule_multiplier"], 2),
                    "behavior_multiplier": round(ranked["behavior_multiplier"], 2),
                    "session_multiplier": round(ranked["session_multiplier"], 2),
                    "customization_multiplier": round(ranked["customization_multiplier"], 2),
                    "cold_start_boost": round(ranked.get("cold_start_boost", 1.0), 2),
                    "is_cold_start": ranked.get("is_cold_start", False),
                    "algorithm_variant": ranked.get("algorithm_variant", "hybrid"),
                    "order_boost_detail": ranked.get("order_boost_detail"),
                    "customization_boost_detail": ranked.get("customization_boost_detail")
                },
                "matched_keywords": ranked["matched_keywords"],
                "reason": reason_result.get("reason", ""),
                "reason_highlight": reason_result.get("highlight", ""),
                "reason_confidence": reason_result.get("confidence", "medium"),
                "semantic_description": item_desc.get("semantic_description", ""),
                "llm_generated": reason_result.get("provider") != "local",
                "explanation": explanation,
                "suggested_customization": suggested_customization
            })

        llm_calls.extend([{"step": 5, "type": "reason", **c} for c in reason_llm_calls])

        reasoning_steps.append({
            "step": 5,
            "name": "æ¨èç†ç”±ä¸å®¢åˆ¶åŒ–å»ºè®®ç”Ÿæˆ",
            "description": f"Top-{min(3, top_k)}ä½¿ç”¨LLMï¼Œé£æ ¼:{reason_style}ï¼Œå«å®¢åˆ¶åŒ–å»ºè®®",
            "input": {"items_count": len(recommendations), "style": reason_style},
            "output": {
                "llm_reasons": len(reason_llm_calls),
                "with_explanation": enable_explainability,
                "with_suggested_customization": enable_behavior
            },
            "duration_ms": round((time.time() - step5_start) * 1000, 2),
            "model": "GPT-4o-mini",
            "provider": "openai"
        })

        total_time = time.time() - start_time

        return {
            "user_id": user_id,
            "session_id": session_id,
            "user_profile": {
                "persona_type": persona_type,
                "description": user_profile.get("description", ""),
                "keywords": user_profile.get("keywords", []),
                "search_query": user_profile.get("search_query", ""),
                "avoid_keywords": user_profile.get("avoid_keywords", []),
                "custom_tags": custom_tags or []
            },
            "context": context or {},
            "experiment": experiment_info,
            "reasoning_steps": reasoning_steps,
            "recommendations": recommendations,
            "llm_info": {
                "provider": self.llm_service.provider_info.get("provider"),
                "model": self.llm_service.provider_info.get("model"),
                "embedding_model": self.vector_service.embedding_service.model,
                "calls": llm_calls,
                "total_llm_calls": len(llm_calls)
            },
            "personalization": {
                "behavior_enabled": enable_behavior,
                "session_enabled": enable_session,
                "ab_test_enabled": enable_ab_test
            },
            "metrics": {
                "total_time_ms": round(total_time * 1000, 2),
                "candidates_evaluated": len(candidates),
                "final_recommendations": len(recommendations),
                "avg_match_score": round(
                    sum(r["match_score"] for r in recommendations) / len(recommendations), 4
                ) if recommendations else 0
            }
        }

    def recommend_with_custom_preference(
        self,
        custom_preference: str,
        user_id: str = None,
        session_id: str = None,
        context: dict = None,
        top_k: int = 6,
        enable_ab_test: bool = True,
        enable_behavior: bool = True,
        enable_session: bool = True
    ) -> dict:
        """
        è‡ªå®šä¹‰åå¥½æ¨è - æ”¯æŒç”¨æˆ·è‡ªç”±æ–‡æœ¬è¾“å…¥

        Args:
            custom_preference: ç”¨æˆ·è‡ªç”±æ–‡æœ¬æè¿°ï¼Œå¦‚"ä½å¡ã€æç¥ã€æ¸…çˆ½çš„é¥®å“"
        """
        start_time = time.time()

        # ç”Ÿæˆé»˜è®¤ID
        user_id = user_id or f"user_{int(time.time())}"
        session_id = session_id or f"session_{int(time.time())}"

        # Step 1: ä½¿ç”¨LLMè§£æç”¨æˆ·è‡ªç”±æ–‡æœ¬åå¥½
        parse_prompt = f"""åˆ†æç”¨æˆ·çš„é¥®å“åå¥½æè¿°ï¼Œæå–å…³é”®éœ€æ±‚ã€‚

ç”¨æˆ·æè¿°ï¼š{custom_preference}

è¾“å‡ºJSONï¼š
{{
    "search_query": "ç”¨äºæœç´¢åŒ¹é…é¥®å“çš„æŸ¥è¯¢è¯­å¥ï¼Œ50å­—ä»¥å†…",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...],
    "avoid_keywords": ["æ’æ–¥å…³é”®è¯"],
    "temperature_hint": "HOT/ICED/null",
    "calorie_preference": "low/medium/high/null",
    "inferred_persona": "æœ€æ¥è¿‘çš„ç”¨æˆ·ç±»å‹: å¥åº·è¾¾äºº/å’–å•¡é‡åº¦ç”¨æˆ·/ç”œå“çˆ±å¥½è€…/å°é²œæ´¾/å®ç”¨ä¸»ä¹‰/å…»ç”Ÿç™½é¢†"
}}"""

        parse_result = self.llm_service.llm.generate_json(parse_prompt, "ä½ æ˜¯ç”¨æˆ·ç ”ç©¶ä¸“å®¶")
        parsed = parse_result.get("content", {})

        if not isinstance(parsed, dict):
            parsed = {
                "search_query": custom_preference,
                "keywords": custom_preference.split("ã€"),
                "avoid_keywords": [],
                "temperature_hint": None,
                "calorie_preference": None,
                "inferred_persona": "å®ç”¨ä¸»ä¹‰"
            }

        # æ„å»ºç”¨æˆ·ç”»åƒ
        user_profile = {
            "persona_type": "è‡ªå®šä¹‰åå¥½",
            "description": custom_preference,
            "keywords": parsed.get("keywords", []),
            "search_query": parsed.get("search_query", custom_preference),
            "avoid_keywords": parsed.get("avoid_keywords", []),
            "customization_keywords": [],
            "inferred_persona": parsed.get("inferred_persona", "å®ç”¨ä¸»ä¹‰"),
            "temperature_hint": parsed.get("temperature_hint"),
            "calorie_preference": parsed.get("calorie_preference"),
            "processing_time_ms": round((time.time() - start_time) * 1000, 2),
            "llm_model": parse_result.get("model", "unknown"),
            "provider": parse_result.get("provider", "unknown")
        }

        # Step 2: ç”¨æˆ·å‘é‡åŒ–
        user_embedding = self.vector_service.get_user_embedding(user_profile)

        # Step 3: å‘é‡å¬å›
        candidates = []
        for sku, item_embedding in self.vector_service.item_embeddings.items():
            similarity = self.vector_service.calculate_similarity(user_embedding, item_embedding)
            candidates.append({"sku": sku, "similarity": similarity})

        candidates.sort(key=lambda x: x["similarity"], reverse=True)

        # Step 4: åº”ç”¨é¢å¤–è¿‡æ»¤ï¼ˆåŸºäºè§£æç»“æœï¼‰
        services = self.experiment_services
        reranked = []

        for candidate in candidates[:top_k * 2]:
            item = self.menu_items[candidate["sku"]]
            base_score = candidate["similarity"]
            rule_multiplier = 1.0

            # æ¸©åº¦åå¥½è¿‡æ»¤
            temp_hint = parsed.get("temperature_hint")
            if temp_hint == "ICED" and Temperature.ICED not in item.available_temperatures:
                rule_multiplier *= 0.5
            elif temp_hint == "HOT" and Temperature.HOT not in item.available_temperatures:
                rule_multiplier *= 0.5

            # å¡è·¯é‡Œåå¥½
            calorie_pref = parsed.get("calorie_preference")
            if calorie_pref == "low" and item.calories > 200:
                rule_multiplier *= 0.7
            elif calorie_pref == "high" and item.calories < 100:
                rule_multiplier *= 0.8

            # æ’æ–¥å…³é”®è¯
            if any(tag in parsed.get("avoid_keywords", []) for tag in item.tags):
                rule_multiplier *= 0.3

            # ä¸Šä¸‹æ–‡åŠ æƒ
            if context:
                time_of_day = context.get("time_of_day")
                season = context.get("season")

                if time_of_day == "morning" and item.category == Category.COFFEE:
                    rule_multiplier *= 1.1
                if season == "summer" and Temperature.ICED in item.available_temperatures:
                    rule_multiplier *= 1.05

            # å†å²è¡Œä¸ºåŠ æƒ
            behavior_multiplier = 1.0
            if enable_behavior:
                order_boost = services["behavior"].get_order_based_recommendation_boost(
                    user_id, item.sku, item.category.value, item.tags, item.base_price
                )
                behavior_multiplier = order_boost["total_boost"]

            # SessionåŠ æƒ
            session_multiplier = 1.0
            if enable_session:
                session_multiplier = services["session"].get_session_boost(
                    session_id, item.tags, item.category.value, item.base_price
                )

            final_score = base_score * rule_multiplier * behavior_multiplier * session_multiplier

            # å…³é”®è¯åŒ¹é…
            user_keywords = set(parsed.get("keywords", []))
            item_keywords = set(item.tags)
            matched_keywords = list(user_keywords & item_keywords)

            reranked.append({
                "sku": candidate["sku"],
                "base_score": base_score,
                "rule_multiplier": rule_multiplier,
                "behavior_multiplier": behavior_multiplier,
                "session_multiplier": session_multiplier,
                "final_score": final_score,
                "matched_keywords": matched_keywords
            })

        reranked.sort(key=lambda x: x["final_score"], reverse=True)

        # Step 5: æ„å»ºæ¨èç»“æœ
        recommendations = []
        for ranked in reranked[:top_k]:
            item = self.menu_items[ranked["sku"]]
            item_desc = self.vector_service.item_texts.get(ranked["sku"], {})

            # ç”Ÿæˆæ¨èç†ç”±
            reason_result = self.llm_service.generate_recommendation_reason(
                item, user_profile, ranked["final_score"], use_llm=(len(recommendations) < 3)
            )

            recommendations.append({
                "item": {
                    "sku": item.sku,
                    "name": item.name,
                    "english_name": item.english_name,
                    "category": item.category.value,
                    "base_price": item.base_price,
                    "description": item.description,
                    "calories": item.calories,
                    "tags": item.tags,
                    "is_new": item.is_new,
                    "is_seasonal": item.is_seasonal,
                    "available_temperatures": [t.value for t in item.available_temperatures],
                    "available_sizes": [s.value for s in item.available_sizes]
                },
                "match_score": round(ranked["final_score"], 4),
                "base_score": round(ranked["base_score"], 4),
                "score_breakdown": {
                    "embedding_similarity": round(ranked["base_score"], 4),
                    "rule_multiplier": round(ranked["rule_multiplier"], 2),
                    "behavior_multiplier": round(ranked["behavior_multiplier"], 2),
                    "session_multiplier": round(ranked["session_multiplier"], 2)
                },
                "matched_keywords": ranked["matched_keywords"],
                "reason": reason_result.get("reason", ""),
                "reason_highlight": reason_result.get("highlight", ""),
                "semantic_description": item_desc.get("semantic_description", "")
            })

        total_time = time.time() - start_time

        return {
            "user_id": user_id,
            "session_id": session_id,
            "custom_preference": custom_preference,
            "parsed_preference": {
                "search_query": parsed.get("search_query", ""),
                "keywords": parsed.get("keywords", []),
                "avoid_keywords": parsed.get("avoid_keywords", []),
                "temperature_hint": parsed.get("temperature_hint"),
                "calorie_preference": parsed.get("calorie_preference"),
                "inferred_persona": parsed.get("inferred_persona")
            },
            "user_profile": user_profile,
            "recommendations": recommendations,
            "llm_info": {
                "provider": self.llm_service.provider_info.get("provider"),
                "model": self.llm_service.provider_info.get("model")
            },
            "metrics": {
                "total_time_ms": round(total_time * 1000, 2),
                "candidates_evaluated": len(candidates),
                "final_recommendations": len(recommendations)
            }
        }


# å•ä¾‹
embedding_recommendation_engine = EmbeddingRecommendationEngine()
